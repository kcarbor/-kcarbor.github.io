---
layout: about
title: about
permalink: /
subtitle:  Ethicist, Philosopher, Computer Scientist | Post-Doctoral Researcher in Ethical, Responsible, and Trustworthy AI | Head of <a href='https://certain.dfki.de'>CERTAIN</a> and Deputy Head at <a href='https://www.dfki.de/nmm'>NMM</a>, <a href='https://www.dfki.de'>DFKI</a>, Saarbr√ºcken, Germany. 

#head of the <a href='https://certain.dfki.de'>Center for European Research in Trusted AI (CERTAIN)</a> and deputy head at the reserach department for <a href='https://www.dfki.de/nmm'>Neuro-Mechanistic Modeling (NMM)</a> at <a href='https://www.dfki.de/web'>German Research Center for Artificial Intelligence (DFKI)</a>. Saarbr√ºcken. Germany. 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p><a href="https://scholar.google.de/citations?user=v3YfPJIAAAAJ"><i class="fa-brands fa-google-scholar"></i> Google Scholar</a></p> <br>
    <p><a href="https://www.linkedin.com/in/kevin-baum-55999580/"><i class="fa-brands fa-linkedin-in"></i> Linkedin</a></p> <br>


news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---
<script src="https://kit.fontawesome.com/568534ed70.js" crossorigin="anonymous"></script>


Hey there! I'm Kevin Baum, a passionate ethicist and computer scientist at the forefront of exploring the ethical dimensions of AI. 

At DFKI, I lead efforts to ensure AI development aligns with societal standards.  
In January 2023, I became deputy head of the¬†research department for¬†[Neuro-Mechanistic Modeling](https://www.dfki.de/nmm)¬†at the [German Research Center for Artifical Intelligence (DFKI)](https://www.dfki.de/web). In December 2023, I became head of the [Center for European Research in Trusted AI (CERTAIN)](https://certain.dfki.de). Since October 2024, I am leading my own research group on [Responsible AI and Machine Ethics (RAIME)](https://dfki.de/en/web/research/research-departments/neuro-mechanistic-modeling/raime).

**Research Interests:** <br>

üîçü§ñ Much of my interdisciplinary work navigates the intricate relationship between AI's __perspicuity attributes__ ‚Äî such as transparency and explainability ‚Äî and __societal desiderata__ including closing responsible gaps, enabling *effective* human oversight, and allowing to detect algorithmic unfairness. In addition to my work at DFKI, I am pursuing these questions primarily within two projects. On the one hand, I am member of the [*Transregional Collaborative Research Centre 248* "Foundations of Perspicuous Software Systems" within the Center for Perspicuous Computing (CPEC)](https://www.perspicuous-computing.science/); on the other hand, I remain associated with the highly interdisciplinary project [*Explainable Intelligent Systems* (EIS)](https://explainable-intelligent.systems/), which is funded by the Volkswagen Foundation. More general challenges of hybrid intelligence, especially how experts can effectively inject their knowledge into reinforcement learning (RL) and in turn draw conclusions from RL-based behaviour, are the subject of my new project *Multi-level Abstractions on Causal Modelling for Enhance Reinforcement Learning* (MAC-MERLin).

üñ•Ô∏èüìä More specifically, I started to do philosophically informed research in the computer science side of things with respect to __algorithmic fairness__ and the quest for __*effective* human oversight__, building on methods from __explainable artificial intelligence (XAI)__ and the emerging field of __mechanistic interpretability__. In a sense, this is part of a broader research question that revolves around the interlocking of normative requirements and technical methods/procedures, which ultimately demand conceptual, normative, and empirical evaluation.  In particular, together with my colleagues at [CERTAIN](https://certain.dfki.de), I am researching how those AI system properties that are commonly subsumed under the label __"Trustworthy AI"__ are operationalized and certified and how this can contribute to appropriate trust in AI and a __healthy trust infrastructure__.

ü§ñüìú My research extends into __machine ethics__, i.e., the quest of integrating moral considerations within AI agents' decision-making frameworks. A significant area of inquiry is embedding __normative reasoning into reinforcement learning architectures__, aiming to create AI agents that __learn sensitivity to normative reasons__. Recently, I revistited the __AI alignment__ research.

ü§î‚öñÔ∏è I also engage with the field of __AI ethics__ more generally. I contribute to the formulation of __ethical guidelines__ for AI development. In doing so, I am currently increasingly addressing the question of how we should make decisions under normative and especially moral uncertainty, with regard to both design and deployment decisions. To this end, I am trying to make productive use of considerations from the field of practical reasoning in order to arrive at decisions that are as reasonable and defendable as possible. To do this, I am placing the concept of justifications at the methodological centre of application-oriented AI ethics research.  

üë®‚Äçüè´üìò Further, I ponder on effective methodologies for __ethical education for computer science students and professionals__. Notably, our course [*Ethics for Nerds*](https://dcms.cs.uni-saarland.de/ethics_23/) won the ["Hochschulperle des Jahres" award from the *German Stifterverband* in 2019](https://saarland-informatics-campus.de/piece-of-news/stifterverband-hochschulperle-des-jahres-2019-fuer-ethics-for-nerds/), which recognizes innovative teaching in higher education.


**What else I do:** <br>

Besides all that, I have also gained practical experience in the __ethical assessment of research projects__, be it as a member and deputy chairman of the [*Commission for the Ethics of Security-Relevant Research* ("Kommission f√ºr die Ethik sicherheitsrelevanter Forschung", KEF)](https://www.uni-saarland.de/verwaltung/wissenschaftliche-integritaet/sicherheitsrelevante-forschung.html) at *Saarland University* (UdS) (from 2020 to 2022), as a member of the [*Ethical Review Board* (ERB)](https://erb.cs.uni-saarland.de/) of *Saarbr√ºcken Informatics Campus* (SIC), or as [__ethical advisor__ of the *DFKI Ethics Team*](https://www.dfki.de/web/ueber-uns/governance/ethik-team) and for an (undisclosed) EU Horizon 2020 project. I am also co-founder of the non-profit association [*Algoright*](https://algoright.de/), an __interdisciplinary think tank__ for good digitalization, which is primarily dedicated to __science communication and ethical consulting__. In addition, I was a permanent expert member for digital ethics of the [__Saarland State Parliament's Enquete Commission__ on *Digitalization in Saarland*](https://www.landtag-saar.de/Downloadfile.ashx?FileId=64456&FileName=So16_1902.pdf).


**You really want to know more?** <br>

All my publications can be found on [Google Scholar](https://scholar.google.de/citations?user=v3YfPJIAAAAJ&hl=de), in the [DBLP](https://dblp.org/pid/132/8396.html), and on my [PhilPeople](https://philpeople.org/profiles/kevin-baum) profile. For a comprehensive overview of my academic and professional journey, here is my [curriculum vitae](/assets/pdf/CV_Baum.pdf).




